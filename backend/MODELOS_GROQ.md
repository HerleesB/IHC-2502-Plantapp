# ü§ñ MODELOS DE GROQ DISPONIBLES

## ‚ö†Ô∏è IMPORTANTE: Modelos con Visi√≥n

Para analizar im√°genes, **DEBES usar un modelo con capacidad de visi√≥n**. No todos los modelos de Groq pueden procesar im√°genes.

---

## ‚úÖ MODELOS CON VISI√ìN (Pueden Procesar Im√°genes)

### 1. llama-3.2-90b-vision-preview
- **Par√°metros**: 90 mil millones
- **Ventajas**: 
  - M√°s preciso en an√°lisis de im√°genes
  - Mejor comprensi√≥n de detalles complejos
  - Respuestas m√°s elaboradas
- **Desventajas**:
  - M√°s lento (8-15 segundos por an√°lisis)
  - Mayor consumo de tokens
- **Cu√°ndo usar**: 
  - Diagn√≥sticos complejos
  - Necesitas m√°xima precisi√≥n
  - No importa el tiempo de espera

### 2. llama-3.2-11b-vision-preview ‚≠ê RECOMENDADO
- **Par√°metros**: 11 mil millones
- **Ventajas**:
  - Mucho m√°s r√°pido (3-6 segundos por an√°lisis)
  - Suficientemente preciso para validaci√≥n de fotos
  - Menor consumo de tokens
- **Desventajas**:
  - Ligeramente menos detallado que el 90B
- **Cu√°ndo usar**:
  - Validaci√≥n de calidad de fotos (tu caso actual)
  - Respuestas r√°pidas
  - Experiencia de usuario fluida

---

## ‚ùå MODELOS SIN VISI√ìN (Solo Texto)

Estos modelos **NO pueden procesar im√°genes**:

- `llama-3.1-70b-versatile` (texto, recomendado para moderaci√≥n)
- `llama-3.1-8b-instant` (texto, muy r√°pido)
- `llama-3.3-70b-versatile` (texto, versi√≥n mejorada)
- `mixtral-8x7b-32768` (texto, contexto largo)

---

## üîß CONFIGURACI√ìN ACTUAL

Tu archivo `.env` ahora est√° configurado as√≠:

```bash
# Modelo para an√°lisis de IM√ÅGENES (validaci√≥n de fotos)
GROQ_MODEL=llama-3.2-11b-vision-preview

# Modelo para TEXTO solamente (moderaci√≥n de comentarios)
GROQ_TEXT_MODEL=llama-3.1-70b-versatile
```

**Esta es la configuraci√≥n √ìPTIMA para tu app.**

---

## üìä COMPARACI√ìN DE RENDIMIENTO

| Aspecto | 11B Vision | 90B Vision |
|---------|------------|------------|
| Velocidad | ‚ö°‚ö°‚ö° 3-6s | ‚ö° 8-15s |
| Precisi√≥n | ‚≠ê‚≠ê‚≠ê Alta | ‚≠ê‚≠ê‚≠ê‚≠ê Muy Alta |
| Tokens/Request | üí∞ 300-500 | üí∞üí∞ 500-800 |
| UX en App | ‚úÖ Excelente | ‚ö†Ô∏è Aceptable |
| Recomendado para | Validaci√≥n fotos | Diagn√≥sticos complejos |

---

## üöÄ C√ìMO CAMBIAR DE MODELO

### Opci√≥n 1: Editar el archivo `.env` (recomendado)

1. Abre: `backend/.env`
2. Cambia la l√≠nea:
   ```bash
   GROQ_MODEL=llama-3.2-11b-vision-preview
   ```
   Por:
   ```bash
   GROQ_MODEL=llama-3.2-90b-vision-preview
   ```
3. **Reinicia el backend** (Ctrl+C y volver a ejecutar)

### Opci√≥n 2: Variable de entorno temporal

```bash
# Windows PowerShell
$env:GROQ_MODEL="llama-3.2-90b-vision-preview"
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Windows CMD
set GROQ_MODEL=llama-3.2-90b-vision-preview
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

---

## üß™ VERIFICAR MODELO ACTUAL

### Desde el navegador:

1. Ve a: http://localhost:8000/config
2. Busca: `"groq_model": "llama-3.2-11b-vision-preview"`

### Desde la consola del backend:

Cuando inicias el servidor, ver√°s:
```
ü§ñ Modelo de Groq (Vision): llama-3.2-11b-vision-preview
üìù Modelo de Groq (Text): llama-3.1-70b-versatile
```

---

## ‚ùì ¬øPor Qu√© No Usar Modelos M√°s Grandes?

**GPT-4 Vision, Claude 3.5 Sonnet, etc.**

Estos modelos **NO est√°n disponibles en Groq** (al menos no en 2024-2025). Groq solo ofrece:
- Modelos de Meta (Llama)
- Modelos de Mistral
- Ning√∫n modelo de OpenAI o Anthropic

---

## üí° RECOMENDACI√ìN PARA TU APP

Para la **validaci√≥n de fotos** (tu caso actual):

‚úÖ **USA: `llama-3.2-11b-vision-preview`**

**Razones:**
1. Suficientemente preciso para decir si una foto est√° bien centrada, iluminada, etc.
2. Respuesta en 3-6 segundos ‚Üí buena experiencia de usuario
3. Menor costo en tokens
4. La app se siente m√°s r√°pida y fluida

Para **diagn√≥sticos completos** de enfermedades (futuro):

‚úÖ **USA: `llama-3.2-90b-vision-preview`**

**Razones:**
1. Necesitas m√°xima precisi√≥n para identificar enfermedades
2. El usuario esperar√° m√°s tiempo para un diagn√≥stico detallado
3. Vale la pena el tiempo extra por la calidad

---

## üîÑ CAMBIO DE CACHE

He actualizado `app/main.py` para que limpie el cache de configuraci√≥n al iniciar:

```python
# Limpiar cache ANTES de cargar configuraci√≥n
get_settings.cache_clear()
settings = get_settings()
```

Ahora los cambios en `.env` se cargar√°n correctamente al reiniciar el backend.

---

## ‚úÖ TODO LISTO

Tu configuraci√≥n actual es:

```
‚úÖ Modelo con visi√≥n: llama-3.2-11b-vision-preview
‚úÖ Modelo de texto: llama-3.1-70b-versatile
‚úÖ Cache limpiado al inicio
‚úÖ Configuraci√≥n verificable en /config
```

**Reinicia el backend y deber√≠as ver el modelo correcto en los logs.**

---

## üìû Si Quieres Probar el Modelo 90B

1. Para el backend (Ctrl+C)
2. Edita `.env`:
   ```bash
   GROQ_MODEL=llama-3.2-90b-vision-preview
   ```
3. Reinicia el backend
4. Prueba la app
5. Compara el tiempo de respuesta

**Luego decide cu√°l prefieres** seg√∫n la experiencia de usuario.

Mi recomendaci√≥n: **Qu√©date con el 11B** para validaci√≥n de fotos. Es perfecto para ese caso de uso. üéØ
